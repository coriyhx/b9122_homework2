{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999cb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2606864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###### QUESTION 1 part a \n",
    "\n",
    "# Web crawling \n",
    "seed_url = \"https://press.un.org/en\"\n",
    "word = 'crisis'\n",
    "urls = [seed_url]    \n",
    "seen = [seed_url]\n",
    "opened = []\n",
    "\n",
    "maxNumpress = 10\n",
    "\n",
    "\n",
    "\n",
    "g = 1\n",
    "\n",
    "while len(urls) > 0 and len(opened) < maxNumpress:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "\n",
    "    except Exception as ex:\n",
    "        continue    #skip code below\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(webpage)\n",
    "\n",
    "    # Web crawlers\n",
    "    for i in soup.find_all('a', href = True):\n",
    "        # First check if it is a press release \n",
    "        tag = str(i)\n",
    "        if tag == '<a href=\"/en/press-release\" hreflang=\"en\">Press Release</a>':\n",
    "            text = soup.get_text()\n",
    "            if word in text:\n",
    "                f = open(str(g)+'.txt', \"w\")\n",
    "                f.write(text)\n",
    "                f.close()\n",
    "                opened.append(curr_url)\n",
    "                g = g + 1 \n",
    "        # find the url\n",
    "        childUrl = i['href']\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        if seed_url in childUrl and childUrl not in seen:\n",
    "            urls.append(childUrl)\n",
    "            seen.append(childUrl)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8064388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.europarl.europa.eu/news/en/press-room/20230929IPR06132/nagorno-karabakh-meps-demand-review-of-eu-relations-with-azerbaijan', 'https://www.europarl.europa.eu/news/en/press-room/20221209IPR64426/eu-long-term-budget-needs-urgent-revision-to-cope-with-current-crises', 'https://www.europarl.europa.eu/news/en/press-room/20210304IPR99207/parliament-gives-green-light-for-new-eu4health-programme', 'https://www.europarl.europa.eu/news/en/press-room/20220909IPR40138/parliament-adopts-new-rules-on-adequate-minimum-wages-for-all-workers-in-the-eu', 'https://www.europarl.europa.eu/news/en/press-room/20230310IPR77232/minimum-income-schemes-increasing-support-accessibility-and-inclusion', 'https://www.europarl.europa.eu/news/en/press-room/20230210IPR74806/green-deal-industrial-plan-securing-the-eu-s-clean-tech-leadership', 'https://www.europarl.europa.eu/news/en/press-room/20230707IPR02421/parliament-adopts-new-rules-to-boost-energy-savings', 'https://www.europarl.europa.eu/news/en/press-room/20220321IPR25913/more-eu-action-needed-for-secure-food-supply', 'https://www.europarl.europa.eu/news/en/press-room/20221209IPR64427/holodomor-parliament-recognises-soviet-starvation-of-ukrainians-as-genocide', 'https://www.europarl.europa.eu/news/en/press-room/20210422IPR02615/civil-protection-faster-eu-response-to-large-scale-emergencies']\n"
     ]
    }
   ],
   "source": [
    "###### QUESTION 1 part b\n",
    "seed_url = 'https://www.europarl.europa.eu/news/en/press-room'\n",
    "word = 'crisis'\n",
    "urls = [seed_url]    \n",
    "seen = [seed_url]\n",
    "opened = []\n",
    "maxNumpress = 10\n",
    "g = 11\n",
    "\n",
    "\n",
    "while len(urls) > 0 and len(opened) < maxNumpress:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "\n",
    "    except Exception as ex:\n",
    "        continue    #skip code below\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(webpage)\n",
    "\n",
    "    # Web crawlers\n",
    "    for i in soup.find_all('span'):\n",
    "        # First check if it is in Plenary session\n",
    "        tag = str(i)\n",
    "        if tag == '<span class=\"ep_name\">Plenary session</span>':\n",
    "            text = soup.get_text()\n",
    "            if word in text:\n",
    "                f = open(str(g)+'.txt', \"w\")\n",
    "                f.write(text)\n",
    "                f.close()\n",
    "                opened.append(curr_url)\n",
    "                g = g + 1 \n",
    "\n",
    "    for k in soup.find_all('a', href = True):\n",
    "        childUrl = k['href']\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        if seed_url in childUrl and childUrl not in seen and '?' not in childUrl:\n",
    "            urls.append(childUrl)\n",
    "            seen.append(childUrl) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9c1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
